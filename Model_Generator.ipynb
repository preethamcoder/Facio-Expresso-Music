{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea1c7edc-d204-4c30-8227-08127c8794b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch==2.3.1 (from torchvision)\n",
      "  Downloading torch-2.3.1-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.18.1-cp311-cp311-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp311-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.0\n",
      "    Uninstalling torch-2.3.0:\n",
      "      Successfully uninstalled torch-2.3.0\n",
      "Successfully installed torch-2.3.1 torchvision-0.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4dd23d-e6d5-407d-b649-572ed1d816ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c85a6bb0-1cbd-42fb-99a7-e43646d63ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.config.list_physical_devices())\n",
    "# tf.config.set_visible_devices(tf.config.list_physical_devices('CUDA'), 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38439c12-d36e-4a8e-8e9a-9ac888412715",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = ImageDataGenerator(rescale=0.255, validation_split=0.1)\n",
    "test_dataloader = ImageDataGenerator(rescale=0.255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92513424-4ebb-4758-8f7e-96aba6521ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25842 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_dataloader.flow_from_directory('train', target_size=(48,48), color_mode='grayscale', batch_size=64, class_mode='categorical', subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cddaf010-6239-4ca1-a277-85367b3f5f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2868 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_dataloader.flow_from_directory('train', target_size=(48,48), color_mode='grayscale', batch_size=64, class_mode='categorical', subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4880fb2c-cd38-4f52-9d73-ab1236a26be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_dataloader.flow_from_directory('test', target_size=(48,48), color_mode='grayscale', batch_size=64, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a317a53-598f-4332-982c-3eaeee9a2f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Here, we are defining a CNN\n",
    "# It will have 3 convolutional layers and 1 fully conneted layer\n",
    "model = Sequential()\n",
    "\n",
    "# Conv 1\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Conv 2\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Conv 3\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21509cb7-c888-4d09-9374-6fbf0e886f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "204d6b38-b3f4-467d-81ad-a8d0483883f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.2201 - loss: 3.4999 - val_accuracy: 0.2514 - val_loss: 1.8290\n",
      "Epoch 2/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 38ms/step - accuracy: 0.2476 - loss: 1.8194 - val_accuracy: 0.3124 - val_loss: 1.7321\n",
      "Epoch 3/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 37ms/step - accuracy: 0.2944 - loss: 1.7426 - val_accuracy: 0.3685 - val_loss: 1.6007\n",
      "Epoch 4/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.3507 - loss: 1.6354 - val_accuracy: 0.4219 - val_loss: 1.4996\n",
      "Epoch 5/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.3929 - loss: 1.5567 - val_accuracy: 0.4561 - val_loss: 1.4631\n",
      "Epoch 6/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4209 - loss: 1.4985 - val_accuracy: 0.4644 - val_loss: 1.4000\n",
      "Epoch 7/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.4388 - loss: 1.4552 - val_accuracy: 0.4888 - val_loss: 1.3553\n",
      "Epoch 8/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.4537 - loss: 1.4112 - val_accuracy: 0.5010 - val_loss: 1.3185\n",
      "Epoch 9/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 51ms/step - accuracy: 0.4727 - loss: 1.3726 - val_accuracy: 0.5052 - val_loss: 1.2987\n",
      "Epoch 10/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 56ms/step - accuracy: 0.4890 - loss: 1.3270 - val_accuracy: 0.5070 - val_loss: 1.2791\n",
      "Epoch 11/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 57ms/step - accuracy: 0.5135 - loss: 1.2749 - val_accuracy: 0.5373 - val_loss: 1.2342\n",
      "Epoch 14/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 56ms/step - accuracy: 0.5251 - loss: 1.2547 - val_accuracy: 0.5443 - val_loss: 1.2150\n",
      "Epoch 15/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 55ms/step - accuracy: 0.5256 - loss: 1.2526 - val_accuracy: 0.5425 - val_loss: 1.1998\n",
      "Epoch 16/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 54ms/step - accuracy: 0.5327 - loss: 1.2200 - val_accuracy: 0.5533 - val_loss: 1.1891\n",
      "Epoch 17/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 54ms/step - accuracy: 0.5400 - loss: 1.2048 - val_accuracy: 0.5575 - val_loss: 1.1753\n",
      "Epoch 18/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 55ms/step - accuracy: 0.5518 - loss: 1.1821 - val_accuracy: 0.5683 - val_loss: 1.1672\n",
      "Epoch 19/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 56ms/step - accuracy: 0.5537 - loss: 1.1735 - val_accuracy: 0.5526 - val_loss: 1.1899\n",
      "Epoch 20/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 55ms/step - accuracy: 0.5548 - loss: 1.1651 - val_accuracy: 0.5596 - val_loss: 1.1572\n",
      "Epoch 21/50\n",
      "\u001b[1m167/404\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.5644 - loss: 1.1483"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 57ms/step - accuracy: 0.5758 - loss: 1.1150 - val_accuracy: 0.5725 - val_loss: 1.1458\n",
      "Epoch 24/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 58ms/step - accuracy: 0.5831 - loss: 1.1074 - val_accuracy: 0.5610 - val_loss: 1.1733\n",
      "Epoch 25/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 63ms/step - accuracy: 0.5816 - loss: 1.1034 - val_accuracy: 0.5659 - val_loss: 1.1792\n",
      "Epoch 26/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 64ms/step - accuracy: 0.5892 - loss: 1.0753 - val_accuracy: 0.5687 - val_loss: 1.1656\n",
      "Epoch 27/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 55ms/step - accuracy: 0.5945 - loss: 1.0731 - val_accuracy: 0.5791 - val_loss: 1.1402\n",
      "Epoch 28/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 60ms/step - accuracy: 0.5947 - loss: 1.0687 - val_accuracy: 0.5579 - val_loss: 1.1780\n",
      "Epoch 29/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 60ms/step - accuracy: 0.6028 - loss: 1.0509 - val_accuracy: 0.5694 - val_loss: 1.1582\n",
      "Epoch 30/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 58ms/step - accuracy: 0.5938 - loss: 1.0569 - val_accuracy: 0.5753 - val_loss: 1.1293\n",
      "Epoch 31/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.6063 - loss: 1.0459 - val_accuracy: 0.5697 - val_loss: 1.1482\n",
      "Epoch 32/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 61ms/step - accuracy: 0.6093 - loss: 1.0210 - val_accuracy: 0.5757 - val_loss: 1.1475\n",
      "Epoch 33/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 66ms/step - accuracy: 0.6148 - loss: 1.0124 - val_accuracy: 0.5715 - val_loss: 1.1621\n",
      "Epoch 34/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 64ms/step - accuracy: 0.6168 - loss: 1.0083 - val_accuracy: 0.5788 - val_loss: 1.1423\n",
      "Epoch 35/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 63ms/step - accuracy: 0.6210 - loss: 1.0069 - val_accuracy: 0.5778 - val_loss: 1.1441\n",
      "Epoch 36/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 64ms/step - accuracy: 0.6204 - loss: 0.9974 - val_accuracy: 0.5785 - val_loss: 1.1545\n",
      "Epoch 37/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 59ms/step - accuracy: 0.6223 - loss: 0.9943 - val_accuracy: 0.5757 - val_loss: 1.1422\n",
      "Epoch 38/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 57ms/step - accuracy: 0.6305 - loss: 0.9759 - val_accuracy: 0.5941 - val_loss: 1.1323\n",
      "Epoch 39/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 60ms/step - accuracy: 0.6299 - loss: 0.9795 - val_accuracy: 0.5952 - val_loss: 1.1286\n",
      "Epoch 40/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 59ms/step - accuracy: 0.6350 - loss: 0.9661 - val_accuracy: 0.5896 - val_loss: 1.1503\n",
      "Epoch 41/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 59ms/step - accuracy: 0.6356 - loss: 0.9624 - val_accuracy: 0.5774 - val_loss: 1.1561\n",
      "Epoch 42/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 59ms/step - accuracy: 0.6333 - loss: 0.9631 - val_accuracy: 0.5798 - val_loss: 1.1523\n",
      "Epoch 43/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 58ms/step - accuracy: 0.6439 - loss: 0.9457 - val_accuracy: 0.5844 - val_loss: 1.1431\n",
      "Epoch 44/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 57ms/step - accuracy: 0.6421 - loss: 0.9471 - val_accuracy: 0.5934 - val_loss: 1.1292\n",
      "Epoch 45/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 57ms/step - accuracy: 0.6389 - loss: 0.9495 - val_accuracy: 0.5833 - val_loss: 1.1525\n",
      "Epoch 46/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 56ms/step - accuracy: 0.6537 - loss: 0.9223 - val_accuracy: 0.5851 - val_loss: 1.1507\n",
      "Epoch 47/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 54ms/step - accuracy: 0.6526 - loss: 0.9209 - val_accuracy: 0.5938 - val_loss: 1.1476\n",
      "Epoch 48/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 56ms/step - accuracy: 0.6571 - loss: 0.9108 - val_accuracy: 0.5914 - val_loss: 1.1442\n",
      "Epoch 49/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 58ms/step - accuracy: 0.6448 - loss: 0.9228 - val_accuracy: 0.5858 - val_loss: 1.1683\n",
      "Epoch 50/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 58ms/step - accuracy: 0.6632 - loss: 0.9061 - val_accuracy: 0.5910 - val_loss: 1.1428\n",
      "Test loss: 1.1318984031677246 / Test accuracy: 0.5915296673774719\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1\n",
    ")\n",
    "score = model.evaluate(test_generator, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "\n",
    "# model.save('emotion_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
