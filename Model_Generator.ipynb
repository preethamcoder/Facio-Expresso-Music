{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea1c7edc-d204-4c30-8227-08127c8794b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch==2.3.1 (from torchvision)\n",
      "  Downloading torch-2.3.1-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.18.1-cp311-cp311-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp311-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.0\n",
      "    Uninstalling torch-2.3.0:\n",
      "      Successfully uninstalled torch-2.3.0\n",
      "Successfully installed torch-2.3.1 torchvision-0.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d4dd23d-e6d5-407d-b649-572ed1d816ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c85a6bb0-1cbd-42fb-99a7-e43646d63ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.config.list_physical_devices())\n",
    "# tf.config.set_visible_devices(tf.config.list_physical_devices('CUDA'), 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38439c12-d36e-4a8e-8e9a-9ac888412715",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = ImageDataGenerator(rescale=0.255, validation_split=0.1)\n",
    "test_dataloader = ImageDataGenerator(rescale=0.255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92513424-4ebb-4758-8f7e-96aba6521ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25842 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_dataloader.flow_from_directory('train', target_size=(48,48), color_mode='grayscale', batch_size=200, class_mode='categorical', subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cddaf010-6239-4ca1-a277-85367b3f5f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2868 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_dataloader.flow_from_directory('train', target_size=(48,48), color_mode='grayscale', batch_size=64, class_mode='categorical', subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4880fb2c-cd38-4f52-9d73-ab1236a26be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_dataloader.flow_from_directory('test', target_size=(48,48), color_mode='grayscale', batch_size=64, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a317a53-598f-4332-982c-3eaeee9a2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we are defining a CNN\n",
    "# It will have 3 convolutional layers and 1 fully conneted layer\n",
    "model = Sequential()\n",
    "\n",
    "# Conv 1\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Conv 2\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Conv 3\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21509cb7-c888-4d09-9374-6fbf0e886f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "204d6b38-b3f4-467d-81ad-a8d0483883f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - accuracy: 0.2129 - loss: 4.2278 - val_accuracy: 0.2514 - val_loss: 1.8324\n",
      "Epoch 2/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 107ms/step - accuracy: 0.2423 - loss: 1.8279 - val_accuracy: 0.2573 - val_loss: 1.7975\n",
      "Epoch 3/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.2721 - loss: 1.7803 - val_accuracy: 0.3291 - val_loss: 1.7134\n",
      "Epoch 4/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 110ms/step - accuracy: 0.3168 - loss: 1.7108 - val_accuracy: 0.3448 - val_loss: 1.6530\n",
      "Epoch 5/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.3553 - loss: 1.6497 - val_accuracy: 0.3933 - val_loss: 1.6102\n",
      "Epoch 6/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.3815 - loss: 1.5902 - val_accuracy: 0.4268 - val_loss: 1.5077\n",
      "Epoch 7/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.4033 - loss: 1.5374 - val_accuracy: 0.4498 - val_loss: 1.4634\n",
      "Epoch 8/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.4229 - loss: 1.4922 - val_accuracy: 0.4609 - val_loss: 1.4223\n",
      "Epoch 9/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.4404 - loss: 1.4597 - val_accuracy: 0.4700 - val_loss: 1.3676\n",
      "Epoch 10/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 114ms/step - accuracy: 0.4522 - loss: 1.4229 - val_accuracy: 0.4714 - val_loss: 1.3659\n",
      "Epoch 11/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.4659 - loss: 1.3906 - val_accuracy: 0.4850 - val_loss: 1.3390\n",
      "Epoch 12/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 113ms/step - accuracy: 0.4791 - loss: 1.3671 - val_accuracy: 0.5063 - val_loss: 1.3017\n",
      "Epoch 13/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 117ms/step - accuracy: 0.4891 - loss: 1.3441 - val_accuracy: 0.5115 - val_loss: 1.2719\n",
      "Epoch 14/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 116ms/step - accuracy: 0.4962 - loss: 1.3200 - val_accuracy: 0.5153 - val_loss: 1.2650\n",
      "Epoch 15/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 120ms/step - accuracy: 0.5014 - loss: 1.2956 - val_accuracy: 0.5234 - val_loss: 1.2398\n",
      "Epoch 16/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - accuracy: 0.5186 - loss: 1.2626 - val_accuracy: 0.5296 - val_loss: 1.2366\n",
      "Epoch 17/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 119ms/step - accuracy: 0.5177 - loss: 1.2581 - val_accuracy: 0.5265 - val_loss: 1.2065\n",
      "Epoch 18/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.5225 - loss: 1.2465 - val_accuracy: 0.5436 - val_loss: 1.2017\n",
      "Epoch 19/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 132ms/step - accuracy: 0.5334 - loss: 1.2304 - val_accuracy: 0.5453 - val_loss: 1.1905\n",
      "Epoch 20/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 147ms/step - accuracy: 0.5455 - loss: 1.1990 - val_accuracy: 0.5457 - val_loss: 1.1874\n",
      "Epoch 21/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 155ms/step - accuracy: 0.5477 - loss: 1.1953 - val_accuracy: 0.5638 - val_loss: 1.1709\n",
      "Epoch 22/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 152ms/step - accuracy: 0.5534 - loss: 1.1828 - val_accuracy: 0.5572 - val_loss: 1.1556\n",
      "Epoch 23/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 144ms/step - accuracy: 0.5565 - loss: 1.1560 - val_accuracy: 0.5645 - val_loss: 1.1718\n",
      "Epoch 24/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.5587 - loss: 1.1777 - val_accuracy: 0.5680 - val_loss: 1.1386\n",
      "Epoch 25/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 136ms/step - accuracy: 0.5736 - loss: 1.1285 - val_accuracy: 0.5718 - val_loss: 1.1501\n",
      "Epoch 26/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 134ms/step - accuracy: 0.5745 - loss: 1.1223 - val_accuracy: 0.5767 - val_loss: 1.1385\n",
      "Epoch 27/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 132ms/step - accuracy: 0.5872 - loss: 1.0995 - val_accuracy: 0.5729 - val_loss: 1.1416\n",
      "Epoch 28/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 133ms/step - accuracy: 0.5914 - loss: 1.0777 - val_accuracy: 0.5778 - val_loss: 1.1266\n",
      "Epoch 29/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.5941 - loss: 1.0759 - val_accuracy: 0.5774 - val_loss: 1.1203\n",
      "Epoch 30/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 134ms/step - accuracy: 0.5986 - loss: 1.0612 - val_accuracy: 0.5760 - val_loss: 1.1322\n",
      "Epoch 31/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 132ms/step - accuracy: 0.5991 - loss: 1.0574 - val_accuracy: 0.5607 - val_loss: 1.1438\n",
      "Epoch 32/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 132ms/step - accuracy: 0.6018 - loss: 1.0483 - val_accuracy: 0.5837 - val_loss: 1.1147\n",
      "Epoch 33/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 131ms/step - accuracy: 0.6081 - loss: 1.0372 - val_accuracy: 0.5764 - val_loss: 1.1187\n",
      "Epoch 34/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.6124 - loss: 1.0239 - val_accuracy: 0.5879 - val_loss: 1.1071\n",
      "Epoch 35/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 133ms/step - accuracy: 0.6175 - loss: 1.0105 - val_accuracy: 0.5823 - val_loss: 1.1103\n",
      "Epoch 36/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.6235 - loss: 0.9949 - val_accuracy: 0.5823 - val_loss: 1.1004\n",
      "Epoch 37/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - accuracy: 0.6265 - loss: 0.9874 - val_accuracy: 0.5948 - val_loss: 1.0917\n",
      "Epoch 38/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.6329 - loss: 0.9720 - val_accuracy: 0.5889 - val_loss: 1.1075\n",
      "Epoch 39/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 128ms/step - accuracy: 0.6380 - loss: 0.9632 - val_accuracy: 0.5865 - val_loss: 1.1017\n",
      "Epoch 40/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - accuracy: 0.6399 - loss: 0.9602 - val_accuracy: 0.5921 - val_loss: 1.1007\n",
      "Epoch 41/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 128ms/step - accuracy: 0.6416 - loss: 0.9339 - val_accuracy: 0.5938 - val_loss: 1.0921\n",
      "Epoch 42/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - accuracy: 0.6499 - loss: 0.9279 - val_accuracy: 0.5938 - val_loss: 1.0979\n",
      "Epoch 43/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.6518 - loss: 0.9283 - val_accuracy: 0.5924 - val_loss: 1.1085\n",
      "Epoch 44/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.6572 - loss: 0.9015 - val_accuracy: 0.6011 - val_loss: 1.0921\n",
      "Epoch 45/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.6604 - loss: 0.8955 - val_accuracy: 0.5910 - val_loss: 1.1051\n",
      "Epoch 46/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.6600 - loss: 0.9011 - val_accuracy: 0.5976 - val_loss: 1.1007\n",
      "Epoch 47/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - accuracy: 0.6675 - loss: 0.8862 - val_accuracy: 0.5934 - val_loss: 1.1090\n",
      "Epoch 48/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 131ms/step - accuracy: 0.6707 - loss: 0.8794 - val_accuracy: 0.5952 - val_loss: 1.1072\n",
      "Epoch 49/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 131ms/step - accuracy: 0.6766 - loss: 0.8608 - val_accuracy: 0.5990 - val_loss: 1.0959\n",
      "Epoch 50/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 134ms/step - accuracy: 0.6688 - loss: 0.8741 - val_accuracy: 0.6032 - val_loss: 1.0961\n",
      "Test loss: 1.1021231412887573 / Test accuracy: 59.80774760246277\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1\n",
    ")\n",
    "score = model.evaluate(test_generator, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]*100}')\n",
    "\n",
    "# model.save('emotion_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
